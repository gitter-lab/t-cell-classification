{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network\n",
    "\n",
    "In this notebook, we will classify T-cell activity using a simple neural network with one fully-connected hidden layer. This model will learn non-linear relationship between image features and the output.\n",
    "\n",
    "We will treat `learning rate`, `batch size` and `neuron number` as three hyper-parameters, and we can use Nested Cross-Validation to tune these values and test the final models. You can learn more about the Nested Cross-Validation scheme in [logistic_regression.ipynb](logistic_regression.ipynb#1.-Nested-Cross-Validation-Scheme). We will use `Keras` with `Tensorflow` backend to implement the neural network.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Data-Preparation\" data-toc-modified-id=\"1.-Data-Preparation-1\">1. Data Preparation</a></span></li><li><span><a href=\"#2.-Model-Tuning/Training\" data-toc-modified-id=\"2.-Model-Tuning/Training-2\">2. Model Tuning/Training</a></span></li><li><span><a href=\"#3.-Model-Testing\" data-toc-modified-id=\"3.-Model-Testing-3\">3. Model Testing</a></span></li><li><span><a href=\"#4.-Summary\" data-toc-modified-id=\"4.-Summary-4\">4. Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "from glob import glob\n",
    "from os.path import basename, join, exists\n",
    "from collections import Counter\n",
    "from json import load, dump\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import Sequence\n",
    "from tensorflow import set_random_seed\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# We set a random seed to make the notebook results consistent\n",
    "RANDOM_SEED = 53715\n",
    "seed(RANDOM_SEED)\n",
    "set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load and group image pixel features into a dictionary. It contains both augmented and unaugmented sets. \n",
    "\n",
    "Similarly to logistic regression models, the pixel features are reshaped to a 1D array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "# Load the pixel matrix for each donor\n",
    "for d in [1, 2, 3, 5, 6]:\n",
    "    no_aug_x, no_aug_y, no_aug_name = [], [], []\n",
    "    aug_x, aug_y, aug_name = [], [], []\n",
    "    \n",
    "    for name in glob(\"./images/sample_images/processed/augmented/donor_{}/*/*.png\".format(d)):\n",
    "        pixel_mat = cv2.imread(name, 0)\n",
    "        pixel_feature = pixel_mat.reshape((1, -1))\n",
    "        \n",
    "        # Add the feature and label to the correct list\n",
    "        base_name = basename(name)\n",
    "        cur_label = 0 if 'noact' in base_name else 1\n",
    "        \n",
    "        if 'r' not in base_name and 'f' not in base_name:\n",
    "            no_aug_x.append(pixel_feature)\n",
    "            no_aug_y.append(cur_label)\n",
    "            no_aug_name.append(base_name)\n",
    "        \n",
    "        aug_x.append(pixel_feature)\n",
    "        aug_y.append(cur_label)\n",
    "        aug_name.append(base_name)\n",
    "\n",
    "    assert(len(aug_x) == len(aug_y))\n",
    "    assert(len(no_aug_x) == len(no_aug_x))\n",
    "    \n",
    "    # Add data for this donor\n",
    "    all_data[d] = {\n",
    "        'no_aug_x': np.vstack(no_aug_x),\n",
    "        'no_aug_y': np.array(no_aug_y),\n",
    "        'no_aug_name': no_aug_name,\n",
    "        'aug_x': np.vstack(aug_x),\n",
    "        'aug_y': np.array(aug_y),\n",
    "        'aug_name': aug_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training a Keras model, we want to have a mechanism to generate our dataset on multiple cores in real time and feed the model. We can make an instance of `keras.utils.Sequence` and customize the data generation rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Implement the DataGenertor class (instance of Sequence), so we can feed the training\n",
    "    model with better paralley computing support.\n",
    "    \n",
    "    In this inherited class, we want to implement __getitem__ and the __len__ methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, batch_size=32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x(array(n,k)): feature matrix\n",
    "            y(array(k)): label array\n",
    "            batch_size(int): number of training samples per epoch\n",
    "        \"\"\"\n",
    "        self.x, self.y = shuffle(x, y, random_state=RANDOM_SEED)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method tells keras how many times to go through the whole sample.\n",
    "        \"\"\"\n",
    "        return int(np.ceil(self.x.shape[0] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        This method generates one batch of data.\n",
    "        \n",
    "        Args:\n",
    "            index(int): Current batch index\n",
    "        \"\"\"\n",
    "        batch_indexes = self.indexes[index * self.batch_size:\n",
    "                                     (index + 1) * self.batch_size]\n",
    "\n",
    "        batch_x = self.x[batch_indexes, :]\n",
    "        batch_y = self.y[batch_indexes, :]\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we want to have a wrapper to build corresponding train/validation/test data generators within the inner loop of our Nested Cross-Validation scheme.\n",
    "\n",
    "We use early stopping in the network training, and the early stopping criteria is based on\n",
    "the performance on validation set with augmented images. The test data for inner CV loop is\n",
    "the same validation set without augmented images. One might argue that the inner loop performance\n",
    "measure is optimistic. Due to the fairly small data size, we designed it in this way to maximize the\n",
    "image size in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data_cv(all_data, vali_did, test_did, batch_size):\n",
    "    \"\"\"\n",
    "    Function to generate all training/validation/test data to fit keras models following the\n",
    "    Nested Cross-Validation scheme. This function is only used in the inner CV loop.\n",
    "    \n",
    "    Args:\n",
    "        all_data(dict): a dictionary containing all augmented and unaugmented images and their lables\n",
    "            {donor_id: {'no_aug_x': array(n,k),\n",
    "                        'no_aug_y': array(k),\n",
    "                        'no_aug_name': list(k),\n",
    "                        'aug_x': array(n,k),\n",
    "                        'aug_y': array(k),\n",
    "                        'aug_name': list(k)\n",
    "                        }}\n",
    "        vali_did(int): donor id for validation\n",
    "        test_did(int): donor id for test\n",
    "        batch_size(int): number of training sample per epoch\n",
    "        \n",
    "    Returns:\n",
    "        train_data_generator(DataGenerator): DataGenerator for training data\n",
    "        vali_data_generator(DataGenerator): DataGenerator for validation data\n",
    "        class_weight(dict): class weight based on label count in the traning data\n",
    "        test_x(array(n,k)): feature matrix for validating the inner loop training\n",
    "        test_y(array(n)): label array for validating the inner loop training\n",
    "    \"\"\"\n",
    "    # Get the training donor ids\n",
    "    train_dids = [i for i in [1, 2, 3, 5, 6] if i != vali_did and i != test_did]\n",
    "    \n",
    "    # Fill the training set\n",
    "    train_x, train_y = [], []\n",
    "    train_label = []\n",
    "    for train_did in train_dids:\n",
    "        train_x.append(all_data[train_did]['aug_x'])\n",
    "        # For Keras model, we need to use one-hot encoding to write the label\n",
    "        train_y.extend([[1, 0] if i == 0 else [0, 1] for i in all_data[train_did]['aug_y']])\n",
    "        train_label.extend(all_data[train_did]['aug_y'].tolist())\n",
    "    train_x = np.vstack(train_x)\n",
    "    train_y = np.vstack(train_y)\n",
    "    \n",
    "    # Fill the early stopping validation set\n",
    "    vali_x = all_data[vali_did]['aug_x']\n",
    "    vali_y = np.vstack([[1, 0] if i == 0 else [0, 1] for i in all_data[vali_did]['aug_y']])\n",
    "    \n",
    "    # Fill the inner loop validation set (test set)\n",
    "    vali_test_x = all_data[vali_did]['no_aug_x']\n",
    "    vali_test_y = np.vstack([[1, 0] if i == 0 else [0, 1] for i in all_data[vali_did]['no_aug_y']])\n",
    "    \n",
    "    # Generate the class weight based on the skewness of training set\n",
    "    count = Counter(train_label)\n",
    "    if count[1] > count[0]:\n",
    "        class_weight = {1: 1.0, 0: count[1]/count[0]}\n",
    "    else:\n",
    "        class_weight = {1: count[0]/count[1], 0: 1.0}\n",
    "    \n",
    "    return (DataGenerator(train_x, train_y, batch_size),\n",
    "            DataGenerator(vali_x, vali_y, batch_size),\n",
    "            class_weight,\n",
    "            vali_test_x,\n",
    "            vali_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Tuning/Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For parameter tuning, we want a function to generate network models with given parameters (`learning rate` and `neuron number`). The hyper-parameter `batch size` is used in `partition_data_cv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_nn_model(lr, num_neuron=128):\n",
    "    \"\"\"\n",
    "    Compile a single neural network model with one hidden layer with\n",
    "    `num_neuron` neurons.\n",
    "    \n",
    "    Args:\n",
    "        lr(float): learning rate\n",
    "        num_neuron(int): number of neurons in the hidden layer\n",
    "        \n",
    "    Returns:\n",
    "        A compiled simple neural network(Keras Sequential Model).\n",
    "    \"\"\"\n",
    "    # Compile our NN model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neuron, activation='relu', name='hidden',\n",
    "                    input_dim=int(78 * 78)))\n",
    "    model.add(Dense(2, activation='softmax', name='output'))\n",
    "    \n",
    "    # Use the recommended parameters for the Adam optimizer\n",
    "    model.compile(optimizer=optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999,\n",
    "                                            epsilon=None, decay=0.0),\n",
    "                  metrics=['accuracy'],\n",
    "                  loss='categorical_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 128)               778880    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 779,138\n",
      "Trainable params: 779,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn = get_simple_nn_model(0.01, 128)\n",
    "snn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_nn_cv(all_data, num_neuron=128, batch_size=32, lr=0.001,\n",
    "                 epoch=1000, nproc=8, verbose=True):\n",
    "    \"\"\"\n",
    "    Main function to train and test a simple neural network in the Nested Cross-Validation\n",
    "    inner loop. This function will have 5 x 4 = 20 runs for each given parameter combination.\n",
    "    \n",
    "    Args:\n",
    "        all_data(dict): a dictionary containing all augmented and unaugmented images and their lables\n",
    "            {donor_id: {'no_aug_x': array(n,k),\n",
    "                        'no_aug_y': array(k),\n",
    "                        'no_aug_name': list(k),\n",
    "                        'aug_x': array(n,k),\n",
    "                        'aug_y': array(k),\n",
    "                        'aug_name': list(k)\n",
    "                        }}\n",
    "        num_neuron(int): number of neurons in the hidden layer\n",
    "        batch_size(int): size of one training batch\n",
    "        lr(float): learning rate\n",
    "        epoch(int): max epoch to train\n",
    "        nproc(int): number of jobs to run in parallel\n",
    "        verbose(bool): if true, this function prints out the training process\n",
    "        \n",
    "    Return:\n",
    "        A result dictionary containing all inner loop training results.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Start training: lr={}, batch_size={}, num_neuron={}\".format(lr, batch_size, num_neuron))\n",
    "    # We stop training when the performance on validation set does not\n",
    "    # improve in 20 continuous epochs\n",
    "    early_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "    # Leave-one-donor-out 5 X 4 runs\n",
    "    results = {}\n",
    "    donors = [1, 2, 3, 5, 6]\n",
    "\n",
    "    for test_did in donors:\n",
    "        if verbose:\n",
    "            print(\"\\nTraining for test donor {}:\".format(test_did))\n",
    "        for vali_did in [i for i in donors if i != test_did]:\n",
    "            if verbose:\n",
    "                print(\"\\t(vali_did: {})\".format(vali_did), end='')\n",
    "            # Keras would retrain the model if we are calling `fit` on the\n",
    "            # same model, so we compile a new model each time before calling\n",
    "            # `fit`\n",
    "            model = get_simple_nn_model(lr, num_neuron=num_neuron)\n",
    "            train_gen, vali_gen, class_weight, vali_test_x, vali_test_y = partition_data_cv(\n",
    "                all_data, vali_did, test_did, batch_size\n",
    "            )\n",
    "\n",
    "            # Train this model\n",
    "            history = model.fit_generator(train_gen, epochs=epoch, verbose=0,\n",
    "                                          callbacks=[early_callback],\n",
    "                                          validation_data=vali_gen,\n",
    "                                          workers=nproc,\n",
    "                                          use_multiprocessing=True,\n",
    "                                          class_weight=class_weight,\n",
    "                                          shuffle=True)\n",
    "\n",
    "            # Evaluate this model (on the inner validation set)\n",
    "            vali_predict = model.predict(vali_test_x)\n",
    "            vali_predict_prob = [x[1] for x in vali_predict]\n",
    "            \n",
    "            vali_y_1d = [np.argmax(i) for i in vali_test_y]\n",
    "            vali_predict_1d = [np.argmax(i) for i in vali_predict]\n",
    "\n",
    "            auc = metrics.roc_auc_score(vali_y_1d, vali_predict_prob)\n",
    "            ap = metrics.average_precision_score(vali_y_1d, vali_predict_prob)\n",
    "            acc = metrics.accuracy_score(vali_y_1d, vali_predict_1d)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\" => performance (AP) = {:.2f}\".format(ap))\n",
    "            \n",
    "            # Record the results\n",
    "            results[str((test_did, vali_did))] = {\n",
    "                'acc': acc,\n",
    "                'ap': ap,\n",
    "                'auc': auc,\n",
    "                'history': history.history\n",
    "            }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training: lr=0.001, batch_size=32, num_neuron=128\n",
      "\n",
      "Training for test donor 1:\n",
      "\t(vali_did: 2) => performance = 0.87\n",
      "\t(vali_did: 3) => performance = 0.27\n",
      "\t(vali_did: 5) => performance = 0.73\n",
      "\t(vali_did: 6) => performance = 0.43\n",
      "\n",
      "Training for test donor 2:\n",
      "\t(vali_did: 1) => performance = 0.12\n",
      "\t(vali_did: 3) => performance = 0.53\n",
      "\t(vali_did: 5) => performance = 0.74\n",
      "\t(vali_did: 6) => performance = 0.49\n",
      "\n",
      "Training for test donor 3:\n",
      "\t(vali_did: 1) => performance = 0.12\n",
      "\t(vali_did: 2) => performance = 0.85\n",
      "\t(vali_did: 5) => performance = 0.83\n",
      "\t(vali_did: 6) => performance = 0.43\n",
      "\n",
      "Training for test donor 5:\n",
      "\t(vali_did: 1) => performance = 0.12\n",
      "\t(vali_did: 2) => performance = 0.87\n",
      "\t(vali_did: 3) => performance = 0.27\n",
      "\t(vali_did: 6) => performance = 0.74\n",
      "\n",
      "Training for test donor 6:\n",
      "\t(vali_did: 1) => performance = 0.25\n",
      "\t(vali_did: 2) => performance = 0.88\n",
      "\t(vali_did: 3) => performance = 0.28\n",
      "\t(vali_did: 5) => performance = 0.73\n"
     ]
    }
   ],
   "source": [
    "# We will use epoch = 1 here to demontrate one parameter combination training\n",
    "result = simple_nn_cv(all_data, num_neuron=128, batch_size=32, lr=0.001, epoch=1, nproc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7309941520467836,\n",
       " 'ap': 0.2848970251716247,\n",
       " 'auc': 0.5108695652173914,\n",
       " 'history': {'val_loss': [4.335861957328826],\n",
       "  'val_acc': [0.7309941520467836],\n",
       "  'loss': [9.066429723392833],\n",
       "  'acc': [0.5625]}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[str((6, 3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can iterate through all the hyper-parameter combinations. The cell below takes **TODO** hours to run even with `epoch=1`. You can skip running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.01, 128, 32)"
     ]
    }
   ],
   "source": [
    "# Here we will use epoch = 1 to demonstrate how to run the tuning for all\n",
    "# parameter combinations\n",
    "\n",
    "lr_candidates = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "batch_size_candidates = [4, 8, 16, 32, 64, 128]\n",
    "num_neuron_candidates = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "lr_candidates = [0.01]\n",
    "batch_size_candidates = [128]\n",
    "num_neuron_candidates = [32]\n",
    "\n",
    "# Record the average performance for each test donor's CV result\n",
    "tids, lrs, bss, nns, accs, aps, aucs = [], [], [], [], [], [], []\n",
    "\n",
    "for lr in lr_candidates:\n",
    "    for bs in batch_size_candidates:\n",
    "        for num_neuron in num_neuron_candidates:\n",
    "            print(str((lr, bs, num_neuron)), end='')\n",
    "            cur_result = simple_nn_cv(all_data, num_neuron=num_neuron, batch_size=bs,\n",
    "                                      lr=lr, epoch=1, nproc=4, verbose=False)\n",
    "            \n",
    "            # Group performance results to individual test donors\n",
    "            temp_result = {}\n",
    "            for tid in [1, 2, 3, 5, 6]:\n",
    "                temp_result[tid] = {'accs': [], 'aps': [], 'aucs': []}\n",
    "\n",
    "            for key in cur_result:\n",
    "                tid = int(re.sub(r'\\((\\d), \\d\\)', r'\\1', key))\n",
    "                # Collect result into corresponding test donors\n",
    "                temp_result[tid]['accs'].append(cur_result[key]['acc'])\n",
    "                temp_result[tid]['aps'].append(cur_result[key]['ap'])\n",
    "                temp_result[tid]['aucs'].append(cur_result[key]['auc'])\n",
    "            \n",
    "            # Compute the average of performance metric\n",
    "            for tid in temp_result:\n",
    "                tids.append(tid)\n",
    "                lrs.append(lr)\n",
    "                bss.append(bs)\n",
    "                nns.append(num_neuron)\n",
    "                accs.append(np.mean(temp_result[tid]['accs']))\n",
    "                aps.append(np.mean(temp_result[tid]['aps']))\n",
    "                aucs.append(np.mean(temp_result[tid]['aucs']))\n",
    "            \n",
    "tuning_result = pd.DataFrame({\n",
    "    'Test Donor': tids,\n",
    "    'Learning Rate': lrs,\n",
    "    'Batch Size': bss,\n",
    "    'Number of Neurons': nns,\n",
    "    'Average of Accuracy': accs,\n",
    "    'Average of Average Precison': aps,\n",
    "    'Average of AUC': aucs\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a pre-trained `tuning_result` with `epoch=100` on this sample image set. It took **TODO** hours to run on **TODO** servers. We will use it to choose the best parameter. The best parameter is determined by the average of average precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test donor</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Average of Accuracy</th>\n",
       "      <th>Average of Average Precison</th>\n",
       "      <th>Average of AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.423184</td>\n",
       "      <td>0.613984</td>\n",
       "      <td>0.586944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.664927</td>\n",
       "      <td>0.413913</td>\n",
       "      <td>0.550030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.702898</td>\n",
       "      <td>0.626671</td>\n",
       "      <td>0.637355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.551093</td>\n",
       "      <td>0.495308</td>\n",
       "      <td>0.626175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.538281</td>\n",
       "      <td>0.542934</td>\n",
       "      <td>0.638921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test donor  Learning rate  Batch size  Number of neurons  \\\n",
       "0           1           0.01         128                 32   \n",
       "1           2           0.01         128                 32   \n",
       "2           3           0.01         128                 32   \n",
       "3           5           0.01         128                 32   \n",
       "4           6           0.01         128                 32   \n",
       "\n",
       "   Average of Accuracy  Average of Average Precison  Average of AUC  \n",
       "0             0.423184                     0.613984        0.586944  \n",
       "1             0.664927                     0.413913        0.550030  \n",
       "2             0.702898                     0.626671        0.637355  \n",
       "3             0.551093                     0.495308        0.626175  \n",
       "4             0.538281                     0.542934        0.638921  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test donor</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Number of neurons</th>\n",
       "      <th>Average of Accuracy</th>\n",
       "      <th>Average of Average Precison</th>\n",
       "      <th>Average of AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.423184</td>\n",
       "      <td>0.613984</td>\n",
       "      <td>0.586944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.664927</td>\n",
       "      <td>0.413913</td>\n",
       "      <td>0.550030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.702898</td>\n",
       "      <td>0.626671</td>\n",
       "      <td>0.637355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.551093</td>\n",
       "      <td>0.495308</td>\n",
       "      <td>0.626175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>0.538281</td>\n",
       "      <td>0.542934</td>\n",
       "      <td>0.638921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Test donor  Learning rate  Batch size  Number of neurons  \\\n",
       "0           1           0.01         128                 32   \n",
       "1           2           0.01         128                 32   \n",
       "2           3           0.01         128                 32   \n",
       "3           5           0.01         128                 32   \n",
       "4           6           0.01         128                 32   \n",
       "\n",
       "   Average of Accuracy  Average of Average Precison  Average of AUC  \n",
       "0             0.423184                     0.613984        0.586944  \n",
       "1             0.664927                     0.413913        0.550030  \n",
       "2             0.702898                     0.626671        0.637355  \n",
       "3             0.551093                     0.495308        0.626175  \n",
       "4             0.538281                     0.542934        0.638921  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through all the rows in the dataframe, and find the row which\n",
    "# has the largest average of average precision for each test donor\n",
    "best_row = {}\n",
    "\n",
    "for i, r in tuning_result.iterrows():\n",
    "    tid = r['Test Donor']\n",
    "    ap = r['Average of Average Precison']\n",
    "    \n",
    "    if tid not in best_row:\n",
    "        best_row[tid] = [i, ap]\n",
    "        continue\n",
    "    \n",
    "    if ap > best_row[tid]:\n",
    "        best_row[tid] = [i, ap]\n",
    "\n",
    "best_para_df = tuning_result.iloc[[best_row[i][0] for i in best_row], :]\n",
    "\n",
    "# Get the best parameter for each test donor [lr, bs, nn]\n",
    "best_parameters = {}\n",
    "for i, r in best_para_df.iterrows():\n",
    "    best_parameters[r['Test Donor']] = [r['Learning Rate'], r['Batch Size'], r['Number of Neurons']]\n",
    "    \n",
    "best_para_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: [0.01, 128.0, 32.0],\n",
       " 2.0: [0.01, 128.0, 32.0],\n",
       " 3.0: [0.01, 128.0, 32.0],\n",
       " 5.0: [0.01, 128.0, 32.0],\n",
       " 6.0: [0.01, 128.0, 32.0]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning `learning rate`, `batch size`, `number of neurons`, we can test the final models regarding to 5 test donors.\n",
    "\n",
    "In this section, we will use the same `DataGenerator` class to feed Keras models. However, since we no long have to validate different parameters, we need to modify the partition function. In the below function `partition_data_test()`, we split the dataset into train/validation(early stopping)/test sets. The validation set is randomly sampled from all training images. Both train and validation set contain augmented images, and each augmented image is in the same set with its original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data_test(all_data, test_did, batch_size):\n",
    "    \"\"\"\n",
    "    Function to generate all training/validation(early stopping)/test data to fit\n",
    "    keras models for testing after cross validation.\n",
    "\n",
    "    The validation and train set are split randomly while it guarantees that\n",
    "    augmented images are partitioned with their original images. The ratio\n",
    "    of train set size and validation set size is 3:1.\n",
    "\n",
    "    Args:\n",
    "        all_data(dict): a dictionary containing all augmented and unaugmented images and their lables\n",
    "            {donor_id: {'no_aug_x': array(n,k),\n",
    "                        'no_aug_y': array(k),\n",
    "                        'no_aug_name': list(k),\n",
    "                        'aug_x': array(n,k),\n",
    "                        'aug_y': array(k)\n",
    "                        'aug_name': list(k)\n",
    "                        }}\n",
    "        test_did(int): donor id for test\n",
    "        batch_size(int): number of training sample per batch\n",
    "            \n",
    "    Returns:\n",
    "        train_data_generator(DataGenerator): DataGenerator for training data\n",
    "        vali_data_generator(DataGenerator): DataGenerator for early stopping\n",
    "        class_weight(dict): class weight based on label count in the traning data\n",
    "        test_x(array(n,k)): feature matrix for final testing\n",
    "        test_y(array(n)): label array for final testing\n",
    "    \"\"\"\n",
    "    # Get all the non-test original names\n",
    "    original_names, all_x, all_y, all_names = [], [], [], []\n",
    "    for did in [i for i in [1, 2, 3, 5, 6] if i != test_did]:\n",
    "        original_names.extend(all_data[did]['no_aug_name'])\n",
    "        all_x.extend(all_data[did]['aug_x'])\n",
    "        all_y.extend(all_data[did]['aug_y'])\n",
    "        all_names.extend(all_data[did]['aug_name'])\n",
    "        \n",
    "    # Vectorize features and labels\n",
    "    all_x = np.vstack(all_x)\n",
    "    all_y = np.array(all_y)\n",
    "\n",
    "    # Now we randomly take 1/4 of it as validation sets\n",
    "    original_names = shuffle(original_names, random_state=RANDOM_SEED)\n",
    "    original_vali_names = original_names[:len(original_names) // 4]\n",
    "    original_train_names = original_names[len(original_names) // 4:]\n",
    "\n",
    "    # Only leave the prefix of the name in the sets\n",
    "    vali_prefix = set(map(lambda x: re.sub(r'(.+_.+_.+_.+_.+_\\d+).+', r'\\1',\n",
    "                                           x),\n",
    "                          original_vali_names))\n",
    "    train_prefix = set(map(lambda x: re.sub(r'(.+_.+_.+_.+_.+_\\d+).+', r'\\1',\n",
    "                                           x),\n",
    "                          original_train_names))\n",
    "\n",
    "    # Put augmented images in the same set as their base images\n",
    "    train_index, vali_index = [], []\n",
    "    for i in range(len(all_names)):\n",
    "        prefix = re.sub(r'(.+_.+_.+_.+_.+_\\d+).+', r'\\1', all_names[i])\n",
    "        if prefix in train_prefix:\n",
    "            train_index.append(i)\n",
    "        elif prefix in vali_prefix:\n",
    "            vali_index.append(i)\n",
    "\n",
    "    # Fill the train/vali/test set\n",
    "    train_x = all_x[train_index]\n",
    "    train_y = np.vstack([[1, 0] if i == 0 else [0, 1] for i in all_y[train_index]])\n",
    "\n",
    "    vali_x = all_x[vali_index]\n",
    "    vali_y = np.vstack([[1, 0] if i == 0 else [0, 1] for i in all_y[vali_index]])\n",
    "\n",
    "    test_x = all_data[test_did]['no_aug_x']\n",
    "    test_y = np.vstack([[1, 0] if i == 0 else [0, 1] for i in all_data[test_did]['no_aug_y']])\n",
    "    \n",
    "    # Generate the class weight based on the skewness of training set\n",
    "    count = Counter(all_y[train_index])\n",
    "\n",
    "    if count[1] > count[0]:\n",
    "        class_weight = {1: 1.0, 0: count[1] / count[0]}\n",
    "    else:\n",
    "        class_weight = {1: count[0] / count[1], 0: 1.0}\n",
    "\n",
    "    # We test performance on the validation set\n",
    "    return (DataGenerator(train_x, train_y, batch_size),\n",
    "            DataGenerator(vali_x, vali_y, batch_size),\n",
    "            class_weight,\n",
    "            test_x,\n",
    "            test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(metric_dict, count_dict):\n",
    "    \"\"\"\n",
    "    Transfer the model performance metric dictionary into a Markdown table.\n",
    "    \n",
    "    Args:\n",
    "        metric_dict(dict): a dictionary encoding model performance statisitcs\n",
    "            and prediction information for all test donors\n",
    "        count_dict(dict): a dinctionary encoding the count of activated and quiescent\n",
    "            samples for each test donor\n",
    "    \n",
    "    Return:\n",
    "        string: a Markdown syntax table\n",
    "    \"\"\"\n",
    "\n",
    "    # Define header and line template\n",
    "    table_str = \"\"\n",
    "    line = \"|{}|{:.2f}%|{:.2f}%|{:.2f}%|{:.2f}%|{:.2f}%|{}|{}|\\n\"\n",
    "    table_str += (\"|Test Donor|Accuracy|Precision|Recall|Average Precision|AUC|Num of Activated|Num of Quiescent|\\n\")\n",
    "    table_str += \"|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\\n\"\n",
    "\n",
    "    for d in [1, 2, 3, 5, 6]:\n",
    "        result = metric_dict[d]\n",
    "        table_str += (line.format(\"donor_{}\".format(d),\n",
    "                                  result['acc'] * 100, result['precision'] * 100,\n",
    "                                  result['recall'] * 100, result['ap'] * 100,\n",
    "                                  result['aroc'] * 100, count_dict[d]['activated'],\n",
    "                                  count_dict[d]['quiescent']))\n",
    "\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the best parameters to train 5 models for 5 test donors individually. In this notebook, we only use `epoch=1` to demonstrate the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(test_did, best_parameters, epoch, nproc):\n",
    "    \"\"\"\n",
    "    Train and test using the best parameter for current test donor.\n",
    "    \n",
    "    Args:\n",
    "        test_did(int): Test donor ID\n",
    "        best_parameters(dict): The best parameter dictionary for each test donor\n",
    "            {test_donor: [lr, num_neuron, batch_size]}\n",
    "        epoch(int): number of epochs to train the model\n",
    "        nproc(int): number of parallel jobs\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary containing the metrics information and predictions:\n",
    "            metrics scores: ['acc': accuracy, 'precision', 'recall', 'ap': average precision,\n",
    "                             'aroc': area under ROC curve, 'pr': PR curve points,\n",
    "                             'roc': ROC curve points]\n",
    "            predicitons: ['y_true': the groundtruth labels, 'y_score': predicted probability]\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the optimal parameter\n",
    "    lr = best_parameters[test_did][0]\n",
    "    num_neuron = int(best_parameters[test_did][1])\n",
    "    batch_size = int(best_parameters[test_did][2])\n",
    "    \n",
    "    print(\"Start testing for test donor {} with parameters ({}, {}, {})...\".format(test_did,\n",
    "                                                                                   lr,\n",
    "                                                                                   num_neuron,\n",
    "                                                                                   batch_size))\n",
    "\n",
    "    # Model set up\n",
    "    model = get_simple_nn_model(lr, num_neuron=num_neuron)\n",
    "    train_gen, vali_gen, class_weight, test_x, test_y = partition_data_test(\n",
    "        all_data, test_did, batch_size\n",
    "    )\n",
    "    early_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    \n",
    "    # Train this model\n",
    "    history = model.fit_generator(train_gen, epochs=epoch, verbose=0,\n",
    "                                  callbacks=[early_callback],\n",
    "                                  validation_data=vali_gen,\n",
    "                                  workers=nproc,\n",
    "                                  use_multiprocessing=True,\n",
    "                                  class_weight=class_weight,\n",
    "                                  shuffle=True)\n",
    "\n",
    "    # Evaluate this model (on the inner validation set)\n",
    "    test_predict = model.predict(test_x)\n",
    "    test_predict_prob = [x[1] for x in test_predict]\n",
    "\n",
    "    test_y_1d = [np.argmax(i) for i in test_y]\n",
    "    test_predict_1d = [np.argmax(i) for i in test_predict]\n",
    "\n",
    "    \n",
    "    # Compute the PR-curve points\n",
    "    precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
    "        test_y_1d,\n",
    "        test_predict_prob,\n",
    "    )\n",
    "\n",
    "    # Compute the roc-curve points\n",
    "    fprs, tprs, roc_thresholds = metrics.roc_curve(test_y_1d, test_predict_prob)\n",
    "    \n",
    "    # Compute other metrics\n",
    "    acc = metrics.accuracy_score(test_y_1d, test_predict_1d)\n",
    "    auc = metrics.roc_auc_score(test_y_1d, test_predict_prob)\n",
    "    ap = metrics.average_precision_score(test_y_1d, test_predict_prob)\n",
    "    print(\"\\t=> acc={:.2f}, ap={:.2f}, auc={:.2f}\\n\".format(acc, ap, auc))\n",
    "\n",
    "    return ({'acc': acc,\n",
    "             'precision': metrics.precision_score(test_y_1d, test_predict_1d),\n",
    "             'recall': metrics.recall_score(test_y_1d, test_predict_1d),\n",
    "             'ap': ap,\n",
    "             'aroc': auc,\n",
    "             'pr': [precisions.tolist(), recalls.tolist(),\n",
    "                    thresholds.tolist()],\n",
    "             'roc': [fprs.tolist(), tprs.tolist(), roc_thresholds.tolist()],\n",
    "             'y_true': test_y_1d,\n",
    "             'y_score': test_predict_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing for test donor 1 with parameters (0.01, 128, 32)...\n",
      "\t=> acc=0.88, ap=0.12, auc=0.50\n",
      "\n",
      "Start testing for test donor 2 with parameters (0.01, 128, 32)...\n",
      "\t=> acc=0.19, ap=0.81, auc=0.50\n",
      "\n",
      "Start testing for test donor 3 with parameters (0.01, 128, 32)...\n",
      "\t=> acc=0.73, ap=0.27, auc=0.50\n",
      "\n",
      "Start testing for test donor 5 with parameters (0.01, 128, 32)...\n",
      "\t=> acc=0.27, ap=0.73, auc=0.50\n",
      "\n",
      "Start testing for test donor 6 with parameters (0.01, 128, 32)...\n",
      "\t=> acc=0.43, ap=0.43, auc=0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "nproc = 4\n",
    "model_performance = {}\n",
    "\n",
    "for test_did in [1, 2, 3, 5, 6]:\n",
    "    model_performance[test_did] = get_score(test_did, best_parameters, epoch, nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the lables for each donor\n",
    "count_dict = {}\n",
    "\n",
    "for d in [1, 2, 3, 5, 6]:\n",
    "    # Do not count augmented images\n",
    "    act_count = len(glob(\"./images/sample_images/processed/augmented/donor_{}/activated/*.png\".format(d))) // 6\n",
    "    qui_count = len(glob(\"./images/sample_images/processed/augmented/donor_{}/quiescent/*.png\".format(d))) // 6\n",
    "    count_dict[d] = {\n",
    "        'activated': act_count,\n",
    "        'quiescent': qui_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|Test Donor|Accuracy|Precision|Recall|Average Precision|AUC|Num of Activated|Num of Quiescent|\n",
       "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
       "|donor_1|87.78%|0.00%|0.00%|12.22%|50.00%|22|158|\n",
       "|donor_2|18.75%|0.00%|0.00%|81.25%|50.00%|65|15|\n",
       "|donor_3|73.10%|0.00%|0.00%|26.90%|50.00%|46|125|\n",
       "|donor_5|27.17%|0.00%|0.00%|72.83%|50.00%|67|25|\n",
       "|donor_6|43.14%|43.14%|100.00%|43.14%|50.00%|44|58|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table summary\n",
    "display(Markdown(make_table(model_performance, count_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have shown how to train, tune and test a simple neural network with one hidden layer to classify T-cell images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
