{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "In this notebook, we will classify T-cell activity by retraining sub-layers of a pre-trained deep CNN model Inception V3. This model will learn non-linear relationship between image features and the output. Also, it is more efficient than training a deep CNN from scratch.\n",
    "\n",
    "Inception V3 comprises multiple Inception modules, where each module can be considered as a concatenated neural network layer. We are interested in exploring if retraining more Inception modules can help performance, so we denote the number of last Inception modules to retrain as $n$ and treat it as a hyper-parameter along with `learning rate` and `batch size`. Then, we can use Nested Cross-Validation to tune these values and test the final models. You can learn more about the Nested Cross-Validation scheme in [logistic_regression.ipynb](logistic_regression.ipynb#1.-Nested-Cross-Validation-Scheme). We will use `Keras` with `Tensorflow` backend to implement the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TODO`\n",
    "\n",
    "- Change the requirement list\n",
    "- Add in-text link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "from glob import glob\n",
    "from os.path import basename, join, exists\n",
    "from os import mkdir\n",
    "from collections import Counter\n",
    "from keras.models import Model\n",
    "from keras.utils import Sequence\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, MaxPooling2D, \\\n",
    "    Activation, BatchNormalization, Conv2D, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from json import dump, load\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Call ggplot2 code from this notebook\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# We set a random seed to make the notebook results consistent\n",
    "RANDOM_SEED = 53715\n",
    "seed(RANDOM_SEED)\n",
    "set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Extract Bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, we will use image pixel feature indirectly. Because we are only retraining the last $n$ layers, it is more efficient to extract image features from higher layers instead of feeding image pixels into the whole CNN model. Then, we can think the last $n$ layers as an independent CNN network and we train it using these extracted features as input.\n",
    "\n",
    "These features extracted from the higher layers are sometimes called \"image feature vector\" or \"bottleneck\". With different $n$, the bottlenecks are different. Since we treat $n$ as a hyper-parameter, we want to generate all versions of bottlenecks corresponding to every value of $n$ (from $1$ to $11$). In our study, we are training this CNN model end-to-end from scratch when $n = 11$. In this case, we can directly use image pixel features. The data preparation for $n = 11$ is discussed in [1.2. Generate Image Pixel Features]().\n",
    "\n",
    "Working with deep CNN is computationally expensive, even for our small subset of sample images. Therefore, even though the code to extract all bottlenecks are included in this notebook, we only generate bottlenecks with $n=1$ and $n=2$ here.\n",
    "\n",
    "![](./plots/bottleneck.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bottleneck(data_dir, image_size, mapping, bottleneck_model,\n",
    "                        image_format='png'):\n",
    "    \"\"\"\n",
    "    Generate bottlenecks for all images in data_dir.\n",
    "\n",
    "    Args:\n",
    "        data_dir(string): path to the data directory. This directory is\n",
    "            expected to have n_class subdirectories, where each contains data\n",
    "            of one class.\n",
    "        image_size(tuple): expected image shape\n",
    "        mapping(dict): a dictionary mapping labels to integers\n",
    "            {\n",
    "            'label_1': 0,\n",
    "            'label_2': 1\n",
    "            }\n",
    "        bottleneck_model(keras.model): the bottleneck model to extract features\n",
    "        image_format(string): the image format, default is png\n",
    "    Return:\n",
    "        x(array(n, k)): bottlenecks for images\n",
    "        y(array(n)): labels corresponding to each row of x\n",
    "        names: the image names corresponding to each row of x\n",
    "    \"\"\"\n",
    "    \n",
    "    features, labels, names = [], [], []\n",
    "\n",
    "    # Load the image name and their labels\n",
    "    for label in mapping:\n",
    "        sub_dir = join(data_dir, label)\n",
    "\n",
    "        if not exists(sub_dir):\n",
    "            print(\"can't find {} directory\".format(label))\n",
    "            continue\n",
    "\n",
    "        for image_name in glob(join(sub_dir, \"*.{}\".format(image_format))):\n",
    "            # Load and resize image\n",
    "            image_data = np.array([resize(imread(image_name, as_gray=True),\n",
    "                                          image_size, mode='constant',\n",
    "                                          anti_aliasing=None)])\n",
    "\n",
    "            # Extract features from the image (generate bottleneck)\n",
    "            # We use [0] because it returns a batch of predictions\n",
    "            bottleneck_features = bottleneck_model.predict(image_data)[0]\n",
    "\n",
    "            features.append(bottleneck_features)\n",
    "            labels.append(mapping[label])\n",
    "            names.append(basename(image_name))\n",
    "\n",
    "    # Format the features\n",
    "    return np.array(features), np.array(labels), np.array(names).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define a wrapper function to generate bottlenecks for each $n$ value. In the pre-trained Inception V3 model with ImageNet weights in Keras uses `mixed*` to denote the concatenated layer of Inception modules. For example, `mixed10` is the concatenated layer of the 11th Inception modules (the last one). We will use this to select the range of retraining layers in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bottleneck_main(pre_layer):\n",
    "    \"\"\"\n",
    "    The main function to pre-generate bottlenecks for different starting layers.\n",
    "    This function saves the bottleneck as npz files encoding three arrays:\n",
    "    extracted features, labels and image names.\n",
    "    \n",
    "    Args:\n",
    "        pre_layer(string): The name of the layer before the starting layer.\n",
    "            For example, if you want to retrain 'mixed10', then pre_layer is\n",
    "            'mixed9'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compile a bottleneck model based on the given pre_layer\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=True)\n",
    "    bottleneck_model = Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(pre_layer).output\n",
    "    )\n",
    "\n",
    "    # The pre-trained Inception model expects (299, 299, 3) input\n",
    "    image_size = (299, 299, 3)\n",
    "    data_dir = \"./images/sample_images/processed/augmented/donor_{}/\"\n",
    "    mapping = {'activated': 1, 'quiescent': 0}\n",
    "    \n",
    "    # Create output directory\n",
    "    if not exists('./images/sample_images/bottlenecks'):\n",
    "        mkdir('./images/sample_images/bottlenecks')\n",
    "\n",
    "    # Save one bottleneck for each donor per layer\n",
    "    for donor in [1, 2, 3, 5, 6]:\n",
    "        print('Start generating {} bottlenecks for donor {}.'.format(pre_layer,\n",
    "                                                                    donor))\n",
    "        features, labels, names = generate_bottleneck(data_dir.format(donor),\n",
    "                                                      image_size, mapping,\n",
    "                                                      bottleneck_model)\n",
    "\n",
    "        np.savez(\n",
    "            \"./images/sample_images/bottlenecks/bottleneck_{}_donor_{}.npz\".format(\n",
    "                pre_layer, donor),\n",
    "            features=features, labels=labels, names=names\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating mixed9 bottlenecks for donor 1.\n",
      "Start generating mixed9 bottlenecks for donor 2.\n",
      "Start generating mixed9 bottlenecks for donor 3.\n",
      "Start generating mixed9 bottlenecks for donor 5.\n",
      "Start generating mixed9 bottlenecks for donor 6.\n"
     ]
    }
   ],
   "source": [
    "# This code takes about 30 minutes\n",
    "make_bottleneck_main('mixed9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating mixed8 bottlenecks for donor 1.\n",
      "Start generating mixed8 bottlenecks for donor 2.\n",
      "Start generating mixed8 bottlenecks for donor 3.\n",
      "Start generating mixed8 bottlenecks for donor 5.\n",
      "Start generating mixed8 bottlenecks for donor 6.\n"
     ]
    }
   ],
   "source": [
    "# This code takes about 30 minutes\n",
    "make_bottleneck_main('mixed8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Extract Image Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $n=11$, we are training the whole Inception V3 model end-to-end so there is not need to extract bottlenecks. Instead, we directly resize the images and use their pixel features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data_main():\n",
    "    \"\"\"\n",
    "    The main function to generate right-size images for training a complete\n",
    "    new Inception v3 model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The pre-trained Inception model expects (299, 299, 3) input\n",
    "    image_size = (299, 299, 3)\n",
    "    data_dir = \"./images/sample_images/processed/augmented/donor_{}/\"\n",
    "    mapping = {'activated': 1, 'quiescent': 0}\n",
    "    \n",
    "    # By our convention to name the \"bottleneck\", the pre_layer here is -1\n",
    "    pre_layer = 'mixed-1'\n",
    "    \n",
    "    # Create output directory\n",
    "    if not exists('./images/sample_images/bottlenecks'):\n",
    "        mkdir('./images/sample_images/bottlenecks')\n",
    "\n",
    "    for donor in [1, 2, 3, 5, 6]:\n",
    "        print('Start generating {} bottlenecks for donor {}.'.format(pre_layer,\n",
    "                                                                    donor))\n",
    "        \n",
    "        features, labels, names = [], [], []\n",
    "\n",
    "        # Load the image name and their labels\n",
    "        for label in mapping:\n",
    "            sub_dir = join(data_dir, label).format(donor)\n",
    "\n",
    "            if not exists(sub_dir):\n",
    "                print(\"can't find {} directory for donor {}\".format(label,\n",
    "                                                                    donor))\n",
    "                continue\n",
    "\n",
    "            for image_name in glob(join(sub_dir, \"*.{}\".format('png'))):\n",
    "                # Load and resize image\n",
    "                image_data = resize(imread(image_name, as_gray=True),\n",
    "                                    image_size, mode='constant',\n",
    "                                    anti_aliasing=None)\n",
    "\n",
    "                features.append(image_data)\n",
    "                labels.append(mapping[label])\n",
    "                names.append(basename(image_name))\n",
    "\n",
    "        np.savez(\n",
    "            \"./images/sample_images/bottlenecks/bottleneck_{}_donor_{}.npz\".format(\n",
    "                pre_layer, donor),\n",
    "            features=np.array(features),\n",
    "            labels=np.array(labels),\n",
    "            names=np.array(names).astype(str)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't include `n=11` (`mixed-1`) in this notebook, we won't run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_train_data_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data Generator Pipeline\n",
    "\n",
    "Similarly to the infrastructure of simple neural network and simple CNN, we want to develop a pipeline to generate training data on multiple cores in real time and feed the model. We can make an instance of `keras.utils.Sequence` and customize the data generation rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Implement the DataGenertor class (instance of Sequence), so we can feed the\n",
    "    training model with better parallel computing support.\n",
    "    \n",
    "    In this inherited class, we want to implement __getitem__ and the __len__\n",
    "    methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, batch_size=32):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x(array(n, k): feature arrays\n",
    "            y(array(n)): label array\n",
    "            batch_size(int): number of training samples per epoch\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x, self.y = shuffle(x, y)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method tells keras how many times to go through the whole sample.\n",
    "        \"\"\"\n",
    "        \n",
    "        return int(np.ceil(self.x.shape[0] / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        This method generates one batch of data.\n",
    "        \n",
    "        Args:\n",
    "            index(int): Current batch index\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_indexes = self.indexes[index * self.batch_size:\n",
    "                                     (index + 1) * self.batch_size]\n",
    "        batch_x = self.x[batch_indexes, :]\n",
    "        batch_y = self.y[batch_indexes, :]\n",
    "\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we want a function to partition the bottlenecks into train and validation sets according to the nested cross-validation scheme.\n",
    "\n",
    "One should note that the `vali_data_generator` and `vali_testing_x` are sampled from the same donor(`vali_did`). `vali_data_generator` is used for early stopping, while `vali_testing_x` is used to evaluate the parameter performance. Arguably this setup makes parameter tuning optimistic, but we want to maximize the samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data_cv(bottleneck_dir, pre_layer, batch_size, test_did, vali_did):\n",
    "    \"\"\"\n",
    "    Make train and vali generator for training and inner performance testing.\n",
    "    \n",
    "    Args:\n",
    "        bottleneck_dir(string): directory containing all bottlenecks\n",
    "        pre_layer(string): one layer before the layer which retraining starts\n",
    "        batch_size(int): batch size for training\n",
    "        test_did(int): donor id for test set\n",
    "        vali_did(int): donor id for validation set\n",
    "        \n",
    "    Returns:\n",
    "        train_data_generator(DataGenerator): DataGenerator for training data\n",
    "        vali_data_generator(DataGenerator): DataGenerator for validation data\n",
    "        class_weight(dict): class weight based on label count in the traning data\n",
    "        vali_testing_x(array(n,k)): feature matrix for evaluating the parameter;\n",
    "            it has no augmented images\n",
    "        vali_testing_y(array(n)): label array for evaluating the parameter;\n",
    "            it has no augmented images\n",
    "    \"\"\"\n",
    "    donors = [1, 2, 3, 5, 6]\n",
    "\n",
    "    # Fill the training set\n",
    "    donors.remove(test_did)\n",
    "    donors.remove(vali_did)\n",
    "    print(\"\\t=> Start splitting data...\")\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "\n",
    "    for d in donors:\n",
    "        npz = join(bottleneck_dir, \"bottleneck_{}_donor_{}.npz\".format(\n",
    "            pre_layer, d\n",
    "        ))\n",
    "        npz = np.load(npz)\n",
    "        train_x.append(npz['features'])\n",
    "        train_y.extend(npz['labels'])\n",
    "\n",
    "    train_x = np.vstack(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    # Count the labels for class weighting\n",
    "    count = Counter(train_y)\n",
    "\n",
    "    # One-hot encoding for the labels\n",
    "    train_y = np.vstack([[0, 1] if l else [1, 0] for l in train_y])\n",
    "\n",
    "    # Fill the validation set for early stopping\n",
    "    npz = join(bottleneck_dir, \"bottleneck_{}_donor_{}.npz\".format(pre_layer,\n",
    "                                                                   vali_did))\n",
    "    npz = np.load(npz)\n",
    "    vali_x = npz['features']\n",
    "    vali_y = np.vstack([[0, 1] if l else [1, 0] for l in npz['labels']])\n",
    "\n",
    "    # Fill the validation set for inner evaluation\n",
    "    # This set is the validation set for early stopping without augmented\n",
    "    # images\n",
    "    vali_testing_names = npz['names']\n",
    "    vali_testing_index = np.array(\n",
    "        [('r' not in n) and ('f' not in n) for n in vali_testing_names]\n",
    "    )\n",
    "    vali_testing_x = npz['features'][vali_testing_index]\n",
    "    vali_testing_y = np.vstack([[0, 1] if l else [1, 0] for l in\n",
    "                                npz['labels'][vali_testing_index]])\n",
    "\n",
    "    # Add class weights\n",
    "    if count[1] > count[0]:\n",
    "        class_weight = {1: 1.0, 0: count[1] / count[0]}\n",
    "    else:\n",
    "        class_weight = {1: count[0] / count[1], 0: 1.0}\n",
    "\n",
    "    return (DataGenerator(train_x, train_y, batch_size),\n",
    "            DataGenerator(vali_x, vali_y, batch_size),\n",
    "            class_weight,\n",
    "            vali_testing_x,\n",
    "            vali_testing_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t=> Start splitting data...\n",
      "train_gen batches: 138, vali_gen batches: 30\n",
      "class_weights: {1: 1.3375796178343948, 0: 1.0}\n",
      "vali_testing_x shape: (80, 8, 8, 2048), vali_testing_y shape: (80, 2)\n"
     ]
    }
   ],
   "source": [
    "# Verify the partition_data function\n",
    "(train_gen, vali_gen, class_weights, vali_testing_x,\n",
    " vali_testing_y) = partition_data('./images/sample_images/bottlenecks',\n",
    "                                  'mixed9',\n",
    "                                  16, 1, 2)\n",
    "\n",
    "print('train_gen batches: {}, vali_gen batches: {}'.format(len(train_gen),\n",
    "                                                           len(vali_gen)))\n",
    "print('class_weights: {}'.format(class_weights))\n",
    "print('vali_testing_x shape: {}, vali_testing_y shape: {}'.format(\n",
    "    vali_testing_x.shape,\n",
    "    vali_testing_y.shape\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Tuning/Training\n",
    "\n",
    "In this section, we want to implement nested cross-validation tuning and training. The hyper-parameters are `learning rate`, `batch size` and $n$. `batch size` is controlled by `partition_data_cv()` and `DataGenerator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Building Network\n",
    "\n",
    "First, we want to build the retraining network. As discussed in [1.1. Extract Bottlenecks](), we split the complete Inception V3 model into two parts; we use the first part to extract bottlenecks, and we use bottlenecks to retrain the second part. Here, we want to have a function to dynamically generate the second part by different values of $n$.\n",
    "\n",
    "It is not easy to split layers of the `InceptionV3` model from `keras.applications.inception_v3`. One alternative is to use the original model by setting un-retraining layers to `untrainable`, but this is not taking advantage of bottleneck cache. Therefore, we can refer to the `Keras` source code of `InceptionV3` to implement our own construction functions.\n",
    "\n",
    "The following functions `conv2d_bn()` and `create_model_multiple_layers()` are referring to [`inception_v3.py`](https://github.com/keras-team/keras/blob/b0f1bb9c7c68e24137a9dc284dc210eb0050a6b4/keras/applications/inception_v3.py) written by the Keras team. The latest version of `inception_v3.py` is maintained at [here](https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py). The original version has some misleading comments, but they are later fixed in the newer version. You can learn more on this [issue](https://github.com/keras-team/keras-applications/issues/39)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1),\n",
    "              name=None):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN.\n",
    "    \n",
    "    Args:\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv2D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv2D`.\n",
    "        strides: strides in `Conv2D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "            \n",
    "    Returns:\n",
    "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    \n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = Activation('relu', name=name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_multiple_layers(layer=1):\n",
    "    \"\"\"\n",
    "    Retrain some of the last layers instead of adding a fully connected layer.\n",
    "\n",
    "    Args:\n",
    "        layer(int): 1 => Retrain mixed10\n",
    "                    2 => Retrain mixed9, 10\n",
    "                    3 => Retrain mixed8, 9 , 10\n",
    "                    4 => Retrain mixed7, 8, 9, 10\n",
    "                    5 => Retrain mixed6, 7, 8, 9, 10\n",
    "                    6 => Retrain mixed5, 6, 7, 8, 9, 10\n",
    "                    7 => Retrain mixed4, 5, 6, 7, 8, 9, 10\n",
    "                    8 => Retrain mixed3, 4, 5, 6, 7, 8, 9, 10\n",
    "                    9 => Retrain mixed2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "                    10 => Retrain mixed1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
    "                    11 => Train the entire Inception v3 from scratch\n",
    "\n",
    "    Return:\n",
    "        train_model: the second part of Inception v3 that we want to retrain\n",
    "            using extracted bottlenecks\n",
    "    \"\"\"\n",
    "\n",
    "    if layer == 11:\n",
    "        # Generate a Inception v3 model without pre-trained weights\n",
    "        return InceptionV3(weights=None, include_top=True, classes=2)\n",
    "\n",
    "    channel_axis = 3\n",
    "\n",
    "    # Constant config diction\n",
    "    config = {\n",
    "        1: ['mixed9', (8, 8, 2048)],\n",
    "        2: ['mixed8', (8, 8, 1280)],\n",
    "        3: ['mixed7', (17, 17, 768)],\n",
    "        4: ['mixed6', (17, 17, 768)],\n",
    "        5: ['mixed5', (17, 17, 768)],\n",
    "        6: ['mixed4', (17, 17, 768)],\n",
    "        7: ['mixed3', (17, 17, 768)],\n",
    "        8: ['mixed2', (35, 35, 288)],\n",
    "        9: ['mixed1', (35, 35, 288)],\n",
    "        10: ['mixed0', (35, 35, 256)]\n",
    "    }\n",
    "\n",
    "    # Create training model\n",
    "    bottleneck_input = Input(shape=config[layer][1])\n",
    "    x = bottleneck_input\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    if layer >= 10:\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1),\n",
    "                                       padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    if layer >= 9:\n",
    "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1),\n",
    "                                       padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed2')\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    if layer >= 8:\n",
    "        branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "        branch3x3dbl = conv2d_bn(\n",
    "            branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "        x = layers.concatenate(\n",
    "            [branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis, name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    if layer >= 7:\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1),\n",
    "                                       padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed4')\n",
    "\n",
    "    # mixed 5 / 6: 17 x 17 x 768\n",
    "    mixed_5_6 = []\n",
    "    if layer >= 6:\n",
    "        mixed_5_6 = [0, 1]\n",
    "    elif layer >= 5:\n",
    "        mixed_5_6 = [1]\n",
    "\n",
    "    for i in mixed_5_6:\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    if layer >= 4:\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = AveragePooling2D((3, 3), strides=(1, 1),\n",
    "                                       padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    if layer >= 3:\n",
    "        branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "        branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                              strides=(2, 2), padding='valid')\n",
    "\n",
    "        branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "        branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "        branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "        branch7x7x3 = conv2d_bn(\n",
    "            branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        branch_pool = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "        x = layers.concatenate(\n",
    "            [branch3x3, branch7x7x3, branch_pool], axis=channel_axis,\n",
    "            name='mixed8')\n",
    "\n",
    "    # mixed 9 / 10 : 8 x 8 x 2048\n",
    "    for i in range(2) if layer >= 2 else [1]:\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = layers.concatenate(\n",
    "            [branch3x3_1, branch3x3_2],\n",
    "            axis=channel_axis, name='mixed9_' + str(i)\n",
    "        )\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = layers.concatenate(\n",
    "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis\n",
    "        )\n",
    "\n",
    "        branch_pool = AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same'\n",
    "        )(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = layers.concatenate(\n",
    "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(9 + i)\n",
    "        )\n",
    "\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    predictions = Dense(2, activation='softmax')(x)\n",
    "    train_model = Model(inputs=bottleneck_input,\n",
    "                        outputs=predictions)\n",
    "\n",
    "    return train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 8, 8, 2048)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_932 (Conv2D)             (None, 8, 8, 448)    917504      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_932 (BatchN (None, 8, 8, 448)    1344        conv2d_932[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_932 (Activation)     (None, 8, 8, 448)    0           batch_normalization_932[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_929 (Conv2D)             (None, 8, 8, 384)    786432      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_933 (Conv2D)             (None, 8, 8, 384)    1548288     activation_932[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_929 (BatchN (None, 8, 8, 384)    1152        conv2d_929[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_933 (BatchN (None, 8, 8, 384)    1152        conv2d_933[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_929 (Activation)     (None, 8, 8, 384)    0           batch_normalization_929[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_933 (Activation)     (None, 8, 8, 384)    0           batch_normalization_933[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_930 (Conv2D)             (None, 8, 8, 384)    442368      activation_929[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_931 (Conv2D)             (None, 8, 8, 384)    442368      activation_929[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_934 (Conv2D)             (None, 8, 8, 384)    442368      activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_935 (Conv2D)             (None, 8, 8, 384)    442368      activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_91 (AveragePo (None, 8, 8, 2048)   0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_928 (Conv2D)             (None, 8, 8, 320)    655360      input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_930 (BatchN (None, 8, 8, 384)    1152        conv2d_930[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_931 (BatchN (None, 8, 8, 384)    1152        conv2d_931[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_934 (BatchN (None, 8, 8, 384)    1152        conv2d_934[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_935 (BatchN (None, 8, 8, 384)    1152        conv2d_935[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_936 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_91[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_928 (BatchN (None, 8, 8, 320)    960         conv2d_928[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_930 (Activation)     (None, 8, 8, 384)    0           batch_normalization_930[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_931 (Activation)     (None, 8, 8, 384)    0           batch_normalization_931[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_934 (Activation)     (None, 8, 8, 384)    0           batch_normalization_934[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_935 (Activation)     (None, 8, 8, 384)    0           batch_normalization_935[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_936 (BatchN (None, 8, 8, 192)    576         conv2d_936[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_928 (Activation)     (None, 8, 8, 320)    0           batch_normalization_928[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_930[0][0]             \n",
      "                                                                 activation_931[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 768)    0           activation_934[0][0]             \n",
      "                                                                 activation_935[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_936 (Activation)     (None, 8, 8, 192)    0           batch_normalization_936[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_928[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_28[0][0]             \n",
      "                                                                 activation_936[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,084,162\n",
      "Trainable params: 6,077,634\n",
      "Non-trainable params: 6,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Test the network constructor\n",
    "model_retrain_mixed10 = create_model_multiple_layers(1)\n",
    "model_retrain_mixed10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 8, 8, 1280)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_941 (Conv2D)             (None, 8, 8, 448)    573440      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_941 (BatchN (None, 8, 8, 448)    1344        conv2d_941[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_941 (Activation)     (None, 8, 8, 448)    0           batch_normalization_941[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_938 (Conv2D)             (None, 8, 8, 384)    491520      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_942 (Conv2D)             (None, 8, 8, 384)    1548288     activation_941[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_938 (BatchN (None, 8, 8, 384)    1152        conv2d_938[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_942 (BatchN (None, 8, 8, 384)    1152        conv2d_942[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_938 (Activation)     (None, 8, 8, 384)    0           batch_normalization_938[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_942 (Activation)     (None, 8, 8, 384)    0           batch_normalization_942[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_939 (Conv2D)             (None, 8, 8, 384)    442368      activation_938[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_940 (Conv2D)             (None, 8, 8, 384)    442368      activation_938[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_943 (Conv2D)             (None, 8, 8, 384)    442368      activation_942[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_944 (Conv2D)             (None, 8, 8, 384)    442368      activation_942[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_92 (AveragePo (None, 8, 8, 1280)   0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_937 (Conv2D)             (None, 8, 8, 320)    409600      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_939 (BatchN (None, 8, 8, 384)    1152        conv2d_939[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_940 (BatchN (None, 8, 8, 384)    1152        conv2d_940[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_943 (BatchN (None, 8, 8, 384)    1152        conv2d_943[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_944 (BatchN (None, 8, 8, 384)    1152        conv2d_944[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_945 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_92[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_937 (BatchN (None, 8, 8, 320)    960         conv2d_937[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_939 (Activation)     (None, 8, 8, 384)    0           batch_normalization_939[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_940 (Activation)     (None, 8, 8, 384)    0           batch_normalization_940[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_943 (Activation)     (None, 8, 8, 384)    0           batch_normalization_943[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_944 (Activation)     (None, 8, 8, 384)    0           batch_normalization_944[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_945 (BatchN (None, 8, 8, 192)    576         conv2d_945[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_937 (Activation)     (None, 8, 8, 320)    0           batch_normalization_937[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_939[0][0]             \n",
      "                                                                 activation_940[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 768)    0           activation_943[0][0]             \n",
      "                                                                 activation_944[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_945 (Activation)     (None, 8, 8, 192)    0           batch_normalization_945[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_937[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_29[0][0]             \n",
      "                                                                 activation_945[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_950 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_950 (BatchN (None, 8, 8, 448)    1344        conv2d_950[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_950 (Activation)     (None, 8, 8, 448)    0           batch_normalization_950[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_947 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_951 (Conv2D)             (None, 8, 8, 384)    1548288     activation_950[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_947 (BatchN (None, 8, 8, 384)    1152        conv2d_947[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_951 (BatchN (None, 8, 8, 384)    1152        conv2d_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_947 (Activation)     (None, 8, 8, 384)    0           batch_normalization_947[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_951 (Activation)     (None, 8, 8, 384)    0           batch_normalization_951[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_948 (Conv2D)             (None, 8, 8, 384)    442368      activation_947[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_949 (Conv2D)             (None, 8, 8, 384)    442368      activation_947[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_952 (Conv2D)             (None, 8, 8, 384)    442368      activation_951[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_953 (Conv2D)             (None, 8, 8, 384)    442368      activation_951[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_93 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_946 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_948 (BatchN (None, 8, 8, 384)    1152        conv2d_948[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_949 (BatchN (None, 8, 8, 384)    1152        conv2d_949[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_952 (BatchN (None, 8, 8, 384)    1152        conv2d_952[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_953 (BatchN (None, 8, 8, 384)    1152        conv2d_953[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_954 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_93[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_946 (BatchN (None, 8, 8, 320)    960         conv2d_946[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_948 (Activation)     (None, 8, 8, 384)    0           batch_normalization_948[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_949 (Activation)     (None, 8, 8, 384)    0           batch_normalization_949[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_952 (Activation)     (None, 8, 8, 384)    0           batch_normalization_952[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_953 (Activation)     (None, 8, 8, 384)    0           batch_normalization_953[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_954 (BatchN (None, 8, 8, 192)    576         conv2d_954[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_946 (Activation)     (None, 8, 8, 320)    0           batch_normalization_946[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_948[0][0]             \n",
      "                                                                 activation_949[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 768)    0           activation_952[0][0]             \n",
      "                                                                 activation_953[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_954 (Activation)     (None, 8, 8, 192)    0           batch_normalization_954[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_946[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_30[0][0]             \n",
      "                                                                 activation_954[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 11,132,034\n",
      "Trainable params: 11,118,978\n",
      "Non-trainable params: 13,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Test the network constructor\n",
    "model_retrain_mixed9_10 = create_model_multiple_layers(2)\n",
    "model_retrain_mixed9_10.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Auto-checkpoint Retraining Process\n",
    "\n",
    "In our study, we used [Cooley](https://www.alcf.anl.gov/user-guides/cooley) to run the 3,520 nested cross-validation inner-loop jobs. Some jobs that retraining more layers are too slow to finish in the time limit (12 hours). Therefore, we added an auto-checkpoint feature to save retraining process after every epoch. Once one job gets evicted, we can resubmit it and continue training.\n",
    "\n",
    "The implementation is to write our own early stopping call back, so it saves the network weights after each epoch. When we implemented this function, there was a [bug](https://github.com/keras-team/keras/issues/11101) of saving weights in the multi-threading context (not solved on 4/1/2019). Our workaround is to save weights using different filenames. The implementation of `MyEarlyStopping` is based on Keras' [`callbacks.py`](https://github.com/keras-team/keras/blob/master/keras/callbacks.py#L733)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This callback and the training function need to know where to pick up\n",
    "# checkpoints, so we define the following two global constants.\n",
    "\n",
    "CONFIG_PATH = \"./temp/retrain_config.json\"\n",
    "WEIGHT_PATH = \"./temp/saved_weights_e{}.h5\"\n",
    "\n",
    "if not exists('./temp'):\n",
    "    mkdir('./temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEarlyStopping(EarlyStopping):\n",
    "    \"\"\"\n",
    "    Subclass of the EarlyStopping callback. Add patience record for auto-\n",
    "    checkpoint feature. Using this callback would add I/O's.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 monitor='val_loss',\n",
    "                 min_delta=0,\n",
    "                 patience=0,\n",
    "                 verbose=0,\n",
    "                 mode='auto',\n",
    "                 baseline=None,\n",
    "                 restore_best_weights=False,\n",
    "                 wait_write_path=CONFIG_PATH,\n",
    "                 weight_write_path=WEIGHT_PATH,\n",
    "                 wait=0):\n",
    "        super(EarlyStopping, self).__init__()\n",
    "\n",
    "        self.monitor = monitor\n",
    "        self.baseline = baseline\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.min_delta = min_delta\n",
    "        self.wait = wait\n",
    "        self.stopped_epoch = 0\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "\n",
    "        # Add a new attribute\n",
    "        self.wait_write_path = wait_write_path\n",
    "        self.weight_write_path = weight_write_path\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            print('EarlyStopping mode %s is unknown, fallback to auto mode.'\n",
    "                  % mode)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "        else:\n",
    "            if 'acc' in self.monitor:\n",
    "                self.monitor_op = np.greater\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "\n",
    "        if self.monitor_op == np.greater:\n",
    "            self.min_delta *= 1\n",
    "        else:\n",
    "            self.min_delta *= -1\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # Allow instances to be re-used\n",
    "        # self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        if self.baseline is not None:\n",
    "            self.best = self.baseline\n",
    "        else:\n",
    "            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = self.get_monitor_value(logs)\n",
    "        if current is None:\n",
    "            return\n",
    "\n",
    "        if self.monitor_op(current - self.min_delta, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                if self.restore_best_weights:\n",
    "                    if self.verbose > 0:\n",
    "                        print('Restoring model weights from the end of '\n",
    "                              'the best epoch')\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "\n",
    "        print(\"epoch: {}, wait: {}, best: {}, current:{}\".format(\n",
    "            epoch, self.wait, self.best, current\n",
    "        ))\n",
    "\n",
    "        # Write the `wait` attribute to the config file\n",
    "        # We also save epoch here so we can reconstruct the weight h5 name\n",
    "        wait_dict = {\"waited_epoch\": self.wait, \"best\": self.best,\n",
    "                     \"epoch\": epoch}\n",
    "        dump(wait_dict, open(self.wait_write_path, 'w'), indent=2)\n",
    "\n",
    "        # Instead of saving model, we only save weights\n",
    "        self.model.save_weights(self.weight_write_path.format(epoch))\n",
    "\n",
    "        # Order matters here. Suppose the system died before saving current\n",
    "        # weights, then we have last weights left. If we did save the current\n",
    "        # weights, then it is fine to delete the previous one.\n",
    "        if exists(self.weight_write_path.format(epoch - 1)):\n",
    "            os.remove(self.weight_write_path.format(epoch - 1))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "\n",
    "    def get_monitor_value(self, logs):\n",
    "        monitor_value = logs.get(self.monitor)\n",
    "        if monitor_value is None:\n",
    "            print(\n",
    "                'Early stopping conditioned on metric `%s` '\n",
    "                'which is not available. Available metrics are: %s' %\n",
    "                (self.monitor, ','.join(list(logs.keys())))\n",
    "            )\n",
    "        return monitor_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Nested Cross-validation\n",
    "\n",
    "In this section, we will implement the real retraining routine and the nested cross-validation scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(train_generator, vali_generator, test_did, vali_did,\n",
    "            vali_testing_x, vali_testing_y, class_weights, train_model,\n",
    "            patience, results, wait_count, best, cont_train, epoch=1, nproc=1,\n",
    "            lr=0.001, native_early_stopping=False, verbose=0, test_name=[]):\n",
    "    \"\"\"\n",
    "    Retrain the given train_model on train data and evaluate the performance on\n",
    "    vali_testing data.\n",
    "\n",
    "    Args:\n",
    "        train_generator(DataGenerator): the training data Sequence\n",
    "        vali_generator(DataGenerator): the validation data Sequence\n",
    "        test_did(int): donor id for the test set\n",
    "        vali_did(int): donor id for the validation set\n",
    "        vali_testing_x(np.array): feature from validation set to evaluate parameters\n",
    "            (no augmented images)\n",
    "        vali_testing_y(np.array): labels from validation set to evaluate parameters\n",
    "            (no arugmented images)\n",
    "        epoch(int): training epoch\n",
    "        nprocs(int): number of workers\n",
    "        lr(float): learning rate\n",
    "        class_weights(dict): class weighting for training\n",
    "            For example, {1: 1.33, 0: 1.0}\n",
    "        train_model(Model): the training model\n",
    "        patience(int): early stopping patience\n",
    "        results(dict): a dictionary to record the training results\n",
    "        naive_early_stopping(bool): whether to use the native early stopping(no\n",
    "            auto checkpoints)\n",
    "        verbose(int): the level of output wordness\n",
    "        test_name([string]): image name for vali_testing_y\n",
    "            \n",
    "    This function does not return any value, but it writes the following dict to\n",
    "    the `results` argument.\n",
    "\n",
    "    {\n",
    "        'acc': accuracy,\n",
    "        'ap': average precision,\n",
    "        'auc': auc roc,\n",
    "        'pr': points to plot the PR curve,\n",
    "        'roc': points to plot the ROC curve,\n",
    "        'history': training history,\n",
    "        'y_true': true y values,\n",
    "        'y_true_name': image names of y_true,\n",
    "        'y_score': predicted y values\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # Compile the model\n",
    "    train_model.compile(optimizer=optimizers.Adam(lr=lr,\n",
    "                                                  beta_1=0.9,\n",
    "                                                  beta_2=0.999,\n",
    "                                                  epsilon=None,\n",
    "                                                  decay=0.0),\n",
    "                        metrics=['accuracy'],\n",
    "                        loss='categorical_crossentropy')\n",
    "    # print(train_model.summary())\n",
    "\n",
    "    # Add early stopping\n",
    "    if native_early_stopping:\n",
    "        # Only use native stopping, no model checkpoing\n",
    "        my_callbacks = [EarlyStopping(monitor='val_loss', patience=patience)]\n",
    "    else:\n",
    "        my_callbacks = [MyEarlyStopping(monitor='val_loss', patience=patience,\n",
    "                                        wait=wait_count, baseline=best)]\n",
    "    # train the model on the given data\n",
    "    # Caveat: the old version of Keras requires argument steps_per_epoch\n",
    "    # and validation_steps\n",
    "    print(\"\\t=> Start training\")\n",
    "    hist = train_model.fit_generator(generator=train_generator,\n",
    "                                     validation_data=vali_generator,\n",
    "                                     steps_per_epoch=len(train_generator),\n",
    "                                     validation_steps=len(vali_generator),\n",
    "                                     epochs=epoch,\n",
    "                                     callbacks=my_callbacks,\n",
    "                                     class_weight=class_weights,\n",
    "                                     verbose=0,\n",
    "                                     use_multiprocessing=True,\n",
    "                                     workers=nproc)\n",
    "\n",
    "    # Evaluate the trained model on the inner validation set\n",
    "    vali_predict = train_model.predict(vali_testing_x)\n",
    "\n",
    "    # Remember the silly precision_curve requires 1d prob array\n",
    "    y_predict_prob = [x[1] for x in vali_predict]\n",
    "    vali_y_1d = [np.argmax(i) for i in vali_testing_y]\n",
    "    vali_predict_1d = [np.argmax(i) for i in vali_predict]\n",
    "\n",
    "    auc = metrics.roc_auc_score(vali_y_1d, y_predict_prob)\n",
    "    ap = metrics.average_precision_score(vali_y_1d, y_predict_prob)\n",
    "    acc = metrics.accuracy_score(vali_y_1d, vali_predict_1d)\n",
    "\n",
    "    precisions, recalls, thresholds = metrics.precision_recall_curve(\n",
    "        vali_y_1d,\n",
    "        y_predict_prob\n",
    "    )\n",
    "\n",
    "    fprs, tprs, roc_thresholds = metrics.roc_curve(vali_y_1d, y_predict_prob)\n",
    "\n",
    "    # Record the results\n",
    "    results[str((test_did, vali_did))] = {\n",
    "        'acc': acc,\n",
    "        'ap': ap,\n",
    "        'auc': auc,\n",
    "        'pr': [precisions.tolist(), recalls.tolist(), thresholds.tolist()],\n",
    "        'roc': [fprs.tolist(), tprs.tolist(), roc_thresholds.tolist()],\n",
    "        'history': hist.history,\n",
    "        # Convert int64 and float32 to int and float\n",
    "        'y_true': list(map(int, vali_y_1d)),\n",
    "        'y_true_name': test_name,\n",
    "        'y_score': list(map(float, y_predict_prob))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_main(pre_layer, lr, batch_size, epoch=500, test_did=None,\n",
    "                          vali_did=None):\n",
    "    \"\"\"\n",
    "    The main function for parameter tuning using nested cross validation.\n",
    "    \n",
    "    Args:\n",
    "        pre_layer(string): one layer before the training layer,\n",
    "            with format mixed\\d+.\n",
    "        lr(float): learning rate\n",
    "        batch_size(int): batch size\n",
    "        test_did(int): the donor id for the test set\n",
    "        vali_did(int): the donor id for the validation set\n",
    "        \n",
    "    This function does not return anything, but saves the training and inner-\n",
    "    loop evaluations in a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Training constants\n",
    "    bottleneck_dir = \"./images/sample_images/bottlenecks\"\n",
    "    \n",
    "    # Translate string pre_layer into the integer we used\n",
    "    # in create_model_multiple_layers()\n",
    "    if '-1' in pre_layer:\n",
    "        num_layer = 11\n",
    "    else:\n",
    "        num_layer = 10 - int(re.sub(r'mixed(\\d+)', r'\\1', pre_layer))\n",
    "    \n",
    "    # Set up early stopping patience and an empty dict to record training results\n",
    "    patience = 20\n",
    "    nproc = 6\n",
    "    results = {}\n",
    "\n",
    "    # Try all 20 combinations in one job if the sets are not given\n",
    "    if not test_did or not vali_did:\n",
    "        # Rotation for different test donor and validation donor\n",
    "        donors = [1, 2, 3, 4, 5, 6]\n",
    "        for test_did in donors:\n",
    "            for vali_did in [i for i in donors if i != test_did]:\n",
    "                print(\"Working on cur combination: test={}, vali={}\".\n",
    "                      format(test_did, vali_did))\n",
    "\n",
    "                (train_gen, vali_gen, class_weights, vali_testing_x,\n",
    "                 vali_testing_y) = partition_data(bottleneck_dir, pre_layer,\n",
    "                                                  batch_size, test_did,\n",
    "                                                  vali_did)\n",
    "\n",
    "                # Generate a brand new model for each training\n",
    "                train_model = create_model_multiple_layers(layer=num_layer)\n",
    "\n",
    "                # Retrain this model and evaluate it on the validation set\n",
    "                retrain(train_gen, vali_gen, test_did, vali_did,\n",
    "                        vali_testing_x, vali_testing_y, class_weights,\n",
    "                        train_model, patience, results, epoch=epoch,\n",
    "                        nproc=nproc, lr=lr)\n",
    "\n",
    "                # Overwrite the results json after each combination\n",
    "                dump(results, open(\"results_{}_{}_{}.json\".format(pre_layer,\n",
    "                                                                  lr,\n",
    "                                                                  batch_size),\n",
    "                                   'w'), indent=2)\n",
    "    else:\n",
    "        # Only train and evaluate following the given vali and test set\n",
    "        print(\"Working on combination: test={}, vali={}\".format(test_did,\n",
    "                                                                vali_did))\n",
    "\n",
    "        (train_gen, vali_gen, class_weights, vali_testing_x,\n",
    "         vali_testing_y) = partition_data(bottleneck_dir, pre_layer,\n",
    "                                          batch_size, test_did, vali_did)\n",
    "\n",
    "        # Check if we should continue training or start a new session\n",
    "        if exists(CONFIG_PATH):\n",
    "            print(\"Found existing config path.\")\n",
    "            # Get the epoch info\n",
    "            config_dict = load(open(CONFIG_PATH, 'r'))\n",
    "            weights_h5 = WEIGHT_PATH.format(config_dict[\"epoch\"])\n",
    "            if exists(weights_h5):\n",
    "                train_model = create_model_multiple_layers(layer=num_layer)\n",
    "                train_model.load_weights(weights_h5)\n",
    "                wait_count = config_dict[\"waited_epoch\"]\n",
    "                best = config_dict[\"best\"]\n",
    "                cont_train = True\n",
    "                print(\"\\t=> Continue training, with wait_count={}, best={}\".\n",
    "                      format(wait_count, best))\n",
    "            else:\n",
    "                print(\"Found config json but no weights '{}'!\".format(\n",
    "                    weights_h5\n",
    "                ))\n",
    "                return\n",
    "\n",
    "        else:\n",
    "            print(\"Start new training.\")\n",
    "            train_model = create_model_multiple_layers(layer=num_layer)\n",
    "            wait_count = 0\n",
    "            cont_train = False\n",
    "            best = None\n",
    "\n",
    "        # Retrain this model and evaluate it on the validation set\n",
    "        retrain(train_gen, vali_gen, test_did, vali_did,\n",
    "                vali_testing_x, vali_testing_y, class_weights,\n",
    "                train_model, patience, results, wait_count, best, cont_train,\n",
    "                epoch=epoch, nproc=nproc, lr=lr)\n",
    "\n",
    "        # Save the result dictionary\n",
    "        dump(results, open('./temp/results_{}_{}_{}_{}_{}.json'.format(\n",
    "            pre_layer, lr, batch_size, test_did, vali_did), 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below tries to run one inner-loop job with hyper-parameters: `learning rate` = 0.01, `batch size` = 32 and $n$ = 1. It only runs for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on combination: test=1, vali=2\n",
      "\t=> Start splitting data...\n",
      "Start new training.\n",
      "\t=> Start training\n",
      "epoch: 0, wait: 0, best: 0.524006990591685, current:0.524006990591685\n"
     ]
    }
   ],
   "source": [
    "cross_validation_main('mixed9', 0.01, 32, epoch=1, test_did=1, vali_did=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 epoch of layer=mixed9, lr=0.01, bs=32, test_id=1 and vali_id=2, we have acc=0.8625 and auc=0.9949, ap=0.9989.\n"
     ]
    }
   ],
   "source": [
    "result_dict = load(open('./temp/results_{}_{}_{}_{}_{}.json'.format(\n",
    "    'mixed9', 0.01, 32, 1, 2), 'r'))\n",
    "\n",
    "print(\"After 1 epoch of layer={}, lr={}, bs={}, test_id={} and vali_id={}, \".format(\n",
    "    'mixed9', 0.01, 32, 1, 2), end='')\n",
    "      \n",
    "print(\"we have acc={:.4f} and auc={:.4f}, ap={:.4f}.\".format(\n",
    "    result_dict[str((1, 2))]['acc'],\n",
    "    result_dict[str((1, 2))]['auc'],\n",
    "    result_dict[str((1, 2))]['ap']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can try to tune the hyper-parameters using nested cross-validation. In our study, we have hyper-parameter candidates: \n",
    "\n",
    "- `layers = [\"mixed-1\", \"mixed0\", ..., \"mixed9\"]`\n",
    "- `lrs = [0.00001, 0.0001, 0.001, 0.01]`\n",
    "- `batch_sizes = [8, 16, 32, 64]`\n",
    "\n",
    "In this notebook, we can reduce the size for each hyper-parameter candidate to $2$. It still requires $2 \\times 2 \\times 2 \\times 5 \\times 4 = 160$ inner jobs.\n",
    "\n",
    "Instead of using a nested for-loop to run $160$ jobs on one cluster, we recommend to split each inner-loop as an independent job and run jobs on different clusters. We will not run the code below in this notebook, but the results are merged and stored at `./resource/transfer_cv_results.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_candidates = ['mixed8', 'mixed9']\n",
    "lr_candidates = [0.001, 0.01]\n",
    "bs_candidates = [16, 32]\n",
    "\n",
    "# Grid search the best parameter\n",
    "donors = [1, 2, 3, 5, 6]\n",
    "for layer in layer_candidates:\n",
    "    for lr in lr_candidates:\n",
    "        for bs in bs_candidates:\n",
    "            for test_did in donors:\n",
    "                for vali_did in [i for i in donors if i != test_did]:\n",
    "                    pass\n",
    "#                    cross_validation_main(layer, lr, bs, epoch=500,\n",
    "#                                          test_did=test_did, vali_did=vali_did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
